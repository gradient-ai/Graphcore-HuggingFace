{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c80779",
   "metadata": {},
   "source": [
    "# Introduction to Optimum-Graphcore: BERT Fine-tuning on IPUs\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/huggingface/optimum-graphcore/blob/main/readme_logo.png?raw=true\" />\n",
    "</p>\n",
    "\n",
    "## Optimum-Graphcore\n",
    "\n",
    "ğŸ¤— Optimum Graphcore is the interface between the ğŸ¤— Transformers library and [Graphcore IPUs](https://www.graphcore.ai/products/ipu).\n",
    "It provides a set of tools enabling model parallelization and loading on IPUs, training and fine-tuning on all the tasks already supported by Transformers while being compatible with the Hugging Face Hub and every model available on it out of the box.\n",
    "\n",
    "ğŸ¤— Optimum Graphcore was designed with one goal in mind: make training and evaluation straightforward for any ğŸ¤— Transformers user while leveraging the complete power of IPUs.\n",
    "\n",
    "\n",
    "## What is an Intelligence Processing Unit (IPU)?\n",
    "Quote from the Hugging Face [blog post](https://huggingface.co/blog/graphcore#what-is-an-intelligence-processing-unit):\n",
    ">IPUs are the processors that power Graphcoreâ€™s IPU-POD datacenter compute systems. This new type of processor is designed to support the very specific computational requirements of AI and machine learning. Characteristics such as fine-grained parallelism, low precision arithmetic, and the ability to handle sparsity have been built into our silicon.\n",
    "\n",
    "> Instead of adopting a SIMD/SIMT architecture like GPUs, Graphcoreâ€™s IPU uses a massively parallel, MIMD architecture, with ultra-high bandwidth memory placed adjacent to the processor cores, right on the silicon die.\n",
    "\n",
    "> This design delivers high performance and new levels of efficiency, whether running todayâ€™s most popular models, such as BERT and EfficientNet, or exploring next-generation AI applications.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cdf60",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook will demonstrate how to fine-tune a pre-trained BERT model with PyTorch on the Graphcore IPU-POD16 system using Optimum Graphcore. We will use a BERT-Large model and fine-tune on the SQuADv1 Question/Answering task.\n",
    "\n",
    "We will show how to take a BERT model written in PyTorch from the Transformers library from HuggingFace and run it on Graphcore IPUs using Optimum Graphcore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81f9be",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "- Paperspace account with access to the Hugging Face IPU runtime\n",
    "- Optimum Graphcore, installed below\n",
    "\n",
    "The Poplar SDK environment and required IPU hardware are already enabled by Paperspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e087c904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:49:49.117204Z",
     "iopub.status.busy": "2022-08-09T23:49:49.116854Z",
     "iopub.status.idle": "2022-08-09T23:50:18.671513Z",
     "shell.execute_reply": "2022-08-09T23:50:18.670415Z",
     "shell.execute_reply.started": "2022-08-09T23:49:49.117136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum[graphcore]\n",
      "  Downloading optimum-1.3.0.tar.gz (93 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.10.1-py3-none-any.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers[sentencepiece]>=4.18.0\n",
      "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.8/dist-packages (from optimum[graphcore]) (1.10.0+cpu)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from optimum[graphcore]) (21.3)\n",
      "Collecting optimum-graphcore\n",
      "  Downloading optimum_graphcore-0.3.1-py3-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.8/150.8 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->optimum[graphcore]) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->optimum[graphcore]) (2.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->optimum[graphcore]) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->optimum[graphcore]) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->optimum[graphcore]) (3.0.9)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m768.2/768.2 kB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.1\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py38-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3>=1.25.10\n",
      "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum-graphcore->optimum[graphcore]) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum-graphcore->optimum[graphcore]) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum-graphcore->optimum[graphcore]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum-graphcore->optimum[graphcore]) (1.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets->optimum-graphcore->optimum[graphcore]) (2.8)\n",
      "Building wheels for collected packages: optimum\n",
      "  Building wheel for optimum (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optimum: filename=optimum-1.3.0-py3-none-any.whl size=116103 sha256=b04891910b1c1fcc4f90dc845905c05a3cf1c411edbaf66a51a7385dc8010e04\n",
      "  Stored in directory: /root/.cache/pip/wheels/a8/49/a9/ab524a92fe1551a7bb40122388362379df296e7997819e1d76\n",
      "Successfully built optimum\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, xxhash, urllib3, sympy, regex, protobuf, pillow, numpy, multidict, humanfriendly, fsspec, frozenlist, filelock, dill, charset-normalizer, async-timeout, yarl, scipy, responses, pyarrow, pandas, multiprocess, huggingface-hub, coloredlogs, aiosignal, transformers, aiohttp, optimum, datasets, optimum-graphcore\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 charset-normalizer-2.1.0 coloredlogs-15.0.1 datasets-2.4.0 dill-0.3.5.1 filelock-3.7.1 frozenlist-1.3.1 fsspec-2022.7.1 huggingface-hub-0.8.1 humanfriendly-10.0 mpmath-1.2.1 multidict-6.0.2 multiprocess-0.70.13 numpy-1.23.1 optimum-1.3.0 optimum-graphcore-0.3.1 pandas-1.4.3 pillow-9.2.0 protobuf-3.20.1 pyarrow-9.0.0 regex-2022.7.25 responses-0.18.0 scipy-1.9.0 sentencepiece-0.1.97 sympy-1.10.1 tokenizers-0.12.1 transformers-4.21.1 urllib3-1.26.11 xxhash-3.0.0 yarl-1.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optimum[graphcore]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058de600-f3e2-488f-bc03-92f8a1ba65f2",
   "metadata": {},
   "source": [
    "We set Hugging Face transformers to version 4.20.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c2e987-a031-4278-9bba-2916ef535583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:18.673247Z",
     "iopub.status.busy": "2022-08-09T23:50:18.673051Z",
     "iopub.status.idle": "2022-08-09T23:50:28.354984Z",
     "shell.execute_reply": "2022-08-09T23:50:28.354194Z",
     "shell.execute_reply.started": "2022-08-09T23:50:18.673224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.20.0\n",
      "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Using cached numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.7.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: tokenizers, urllib3, typing-extensions, tqdm, regex, pyyaml, pyparsing, numpy, idna, filelock, charset-normalizer, certifi, requests, packaging, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.11\n",
      "    Uninstalling urllib3-1.26.11:\n",
      "      Successfully uninstalled urllib3-1.26.11\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.7.25\n",
      "    Uninstalling regex-2022.7.25:\n",
      "      Successfully uninstalled regex-2022.7.25\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.8\n",
      "    Uninstalling idna-2.8:\n",
      "      Successfully uninstalled idna-2.8\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.7.1\n",
      "    Uninstalling filelock-3.7.1:\n",
      "      Successfully uninstalled filelock-3.7.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.1.0\n",
      "    Uninstalling charset-normalizer-2.1.0:\n",
      "      Successfully uninstalled charset-normalizer-2.1.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2019.11.28\n",
      "    Uninstalling certifi-2019.11.28:\n",
      "      Successfully uninstalled certifi-2019.11.28\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.8.1\n",
      "    Uninstalling huggingface-hub-0.8.1:\n",
      "      Successfully uninstalled huggingface-hub-0.8.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.1\n",
      "    Uninstalling transformers-4.21.1:\n",
      "      Successfully uninstalled transformers-4.21.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.25.45 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2022.6.15 charset-normalizer-2.1.0 filelock-3.7.1 huggingface-hub-0.8.1 idna-3.3 numpy-1.23.1 packaging-21.3 pyparsing-3.0.9 pyyaml-6.0 regex-2022.7.25 requests-2.28.1 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.20.0 typing-extensions-4.3.0 urllib3-1.26.11\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers==4.20.0 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81f8d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:28.356923Z",
     "iopub.status.busy": "2022-08-09T23:50:28.356711Z",
     "iopub.status.idle": "2022-08-09T23:50:30.123723Z",
     "shell.execute_reply": "2022-08-09T23:50:30.123103Z",
     "shell.execute_reply.started": "2022-08-09T23:50:28.356903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n"
     ]
    }
   ],
   "source": [
    "import optimum.graphcore\n",
    "print(optimum.graphcore.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86a3e1",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\n",
    "### BERT\n",
    "\n",
    "BERT fine-tuning is when you train a BERT model on a supervised learning task on a relatively small amount of data, by using starting weights obtained from pre-training on a large, generic text corpus. Pre-training of BERT requires a lot of unlabelled data (for instance all of Wikipedia + thousands of books) and a lot of compute. It is expensive and time-consuming, but after pre-training BERT will have learned an extremely good language model that can be fine-tuned on downstream tasks with small amount of labeled data, achieving great results.\n",
    "\n",
    "\n",
    "![bert.png](images/bert.png)\n",
    "\n",
    "\n",
    "In this notebook we will fine-tune BERT (pre-trained on IPU with the Wikipedia dataset) on a question answering task called SQuAD. Then we will perform inference on the accompanying validation dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefc3902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:30.125241Z",
     "iopub.status.busy": "2022-08-09T23:50:30.124952Z",
     "iopub.status.idle": "2022-08-09T23:50:30.129030Z",
     "shell.execute_reply": "2022-08-09T23:50:30.128424Z",
     "shell.execute_reply.started": "2022-08-09T23:50:30.125222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from datasets import load_dataset, load_metric\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# To run on IPU we import popart and poptorch packages\n",
    "from optimum.graphcore import IPUConfig, IPUTrainer, IPUTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4440fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:30.129906Z",
     "iopub.status.busy": "2022-08-09T23:50:30.129717Z",
     "iopub.status.idle": "2022-08-09T23:50:30.134553Z",
     "shell.execute_reply": "2022-08-09T23:50:30.133891Z",
     "shell.execute_reply.started": "2022-08-09T23:50:30.129882Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7415744",
   "metadata": {},
   "source": [
    "## 1. Get the data\n",
    "\n",
    "\n",
    "**What is SQuAD?**\n",
    "\n",
    "> Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
    "\n",
    "From https://rajpurkar.github.io/SQuAD-explorer/\n",
    "\n",
    "Basically you train a model to take a question and read a passage of text and predict the start and end positions of where that answer lies in the passage. The image below shows an example from the dataset:\n",
    "\n",
    "\n",
    "\n",
    "(Source: [Rajpurkar GitHub](https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/Normans.html))\n",
    "\n",
    "For the case of SQuADv1 there are no unanswerable questions in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368087c6",
   "metadata": {},
   "source": [
    "We use the ğŸ¤— `datasets` package to automatically download the SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53501b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:30.135442Z",
     "iopub.status.busy": "2022-08-09T23:50:30.135264Z",
     "iopub.status.idle": "2022-08-09T23:50:39.949252Z",
     "shell.execute_reply": "2022-08-09T23:50:39.948440Z",
     "shell.execute_reply.started": "2022-08-09T23:50:30.135425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbd676384d449f993908710fb627ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabf1bcdb696404599e16ace5ba28e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e48b3a91134ff4aceb6eea25b7cc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5c809262c646fca66a0b88a7dfd4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38251faabe0941f7bb6bcf3d65b8dd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca401b264912461d8fafb9cf21a8dbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768d7468c2f14e1da3712dc868003dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05359e88dd164a598c09d3d0aef0699e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1dbd46285644269fc6541b64aca072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db88a6",
   "metadata": {},
   "source": [
    "The SQuAD dataset consists of pre-defined training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8269c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:39.950525Z",
     "iopub.status.busy": "2022-08-09T23:50:39.950353Z",
     "iopub.status.idle": "2022-08-09T23:50:39.958794Z",
     "shell.execute_reply": "2022-08-09T23:50:39.958199Z",
     "shell.execute_reply.started": "2022-08-09T23:50:39.950508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5eeda4",
   "metadata": {},
   "source": [
    "Each row in the data consists of a passage of text - `context` - a question about the passage - `question` - and the answer(s) to the question - `answers`. The latter consists of the text in the passage and the start position in the text.\n",
    "\n",
    "Here is an example row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d928f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:39.961568Z",
     "iopub.status.busy": "2022-08-09T23:50:39.961373Z",
     "iopub.status.idle": "2022-08-09T23:50:39.965800Z",
     "shell.execute_reply": "2022-08-09T23:50:39.965249Z",
     "shell.execute_reply.started": "2022-08-09T23:50:39.961551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56de5ef44396321400ee2861',\n",
       " 'title': 'Institute_of_technology',\n",
       " 'context': 'Institutes of technology in Venezuela were developed in the 1950s as an option for post-secondary education in technical and scientific courses, after the polytechnic French concepts. At that time, technical education was considered essential for the development of a sound middle class economy.',\n",
       " 'question': 'What type of economy was technical education in Venezuela intended to support?',\n",
       " 'answers': {'text': ['middle class'], 'answer_start': [274]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10016]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1eca0",
   "metadata": {},
   "source": [
    "**How do we preprocess this data to train it with a deep learning model?**\n",
    "\n",
    "We need to `tokenize` the text to turn it from words into numbers. This is done using `transformers.BertTokenizer`. Let's use this to tokenize a shortened version of the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b9d67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:39.968582Z",
     "iopub.status.busy": "2022-08-09T23:50:39.968423Z",
     "iopub.status.idle": "2022-08-09T23:50:41.029453Z",
     "shell.execute_reply": "2022-08-09T23:50:41.028692Z",
     "shell.execute_reply.started": "2022-08-09T23:50:39.968566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e8fd41adf540edb4df20d5ea298a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cf75be3ecd492f9200fe168f3b8923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a66f4638d849dfbb55de1bf038d206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564e7a86595343ef9c8eaff951c591b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from squad_preprocessing import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce8edb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.032062Z",
     "iopub.status.busy": "2022-08-09T23:50:41.031865Z",
     "iopub.status.idle": "2022-08-09T23:50:41.048898Z",
     "shell.execute_reply": "2022-08-09T23:50:41.048275Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.032044Z"
    }
   },
   "outputs": [],
   "source": [
    "example = {\"context\": \"Institutes of technology in Venezuela were developed in the 1950s\",\n",
    "           \"question\": \"When were Institutes of technology developed?\"}\n",
    "tokenized_example = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=32,\n",
    "        stride=16,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa946365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.051069Z",
     "iopub.status.busy": "2022-08-09T23:50:41.050904Z",
     "iopub.status.idle": "2022-08-09T23:50:41.054752Z",
     "shell.execute_reply": "2022-08-09T23:50:41.054184Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.051051Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa909d4",
   "metadata": {},
   "source": [
    "Let's look at the `input_ids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c1babc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.056695Z",
     "iopub.status.busy": "2022-08-09T23:50:41.056537Z",
     "iopub.status.idle": "2022-08-09T23:50:41.060439Z",
     "shell.execute_reply": "2022-08-09T23:50:41.059851Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.056679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2043,\n",
       " 2020,\n",
       " 12769,\n",
       " 1997,\n",
       " 2974,\n",
       " 2764,\n",
       " 1029,\n",
       " 102,\n",
       " 12769,\n",
       " 1997,\n",
       " 2974,\n",
       " 1999,\n",
       " 8326,\n",
       " 2020,\n",
       " 2764,\n",
       " 1999,\n",
       " 1996,\n",
       " 4856,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803b71d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.062391Z",
     "iopub.status.busy": "2022-08-09T23:50:41.062236Z",
     "iopub.status.idle": "2022-08-09T23:50:41.065805Z",
     "shell.execute_reply": "2022-08-09T23:50:41.065263Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.062376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] when were institutes of technology developed? [SEP] institutes of technology in venezuela were developed in the 1950s [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_example.input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa1fbf",
   "metadata": {},
   "source": [
    "As you can see in the decoded version, the question is placed at the start followed by a `[SEP]` token, then the context, followed by padding if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba329d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.067637Z",
     "iopub.status.busy": "2022-08-09T23:50:41.067481Z",
     "iopub.status.idle": "2022-08-09T23:50:41.070148Z",
     "shell.execute_reply": "2022-08-09T23:50:41.069596Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.067622Z"
    }
   },
   "outputs": [],
   "source": [
    "from squad_preprocessing import prepare_train_features, prepare_validation_features, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "176caef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:41.072072Z",
     "iopub.status.busy": "2022-08-09T23:50:41.071916Z",
     "iopub.status.idle": "2022-08-09T23:51:45.475466Z",
     "shell.execute_reply": "2022-08-09T23:51:45.474592Z",
     "shell.execute_reply.started": "2022-08-09T23:50:41.072056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596ac67f50b3409cb1210caa4162a59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e7f589c8fa4082b437ae17cf27585d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"].map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=datasets[\"train\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "\n",
    "# Create validation features from dataset\n",
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=datasets[\"validation\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf80ea",
   "metadata": {},
   "source": [
    "## 2. Get the BERT model from `transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb95706",
   "metadata": {},
   "source": [
    "Create the model on the host. We can use `from_pretrained` to load pretrained checkpoints from the HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61f65ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:45.483369Z",
     "iopub.status.busy": "2022-08-09T23:51:45.483180Z",
     "iopub.status.idle": "2022-08-09T23:51:57.803522Z",
     "shell.execute_reply": "2022-08-09T23:51:57.802903Z",
     "shell.execute_reply.started": "2022-08-09T23:51:45.483348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a7a9cc322e4ab4a79a47649eb33a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/703 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd291e071e84c57b89013befe725bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Graphcore/bert-large-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at Graphcore/bert-large-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.BertForQuestionAnswering.from_pretrained(\"Graphcore/bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4976351",
   "metadata": {},
   "source": [
    "**Now we are ready to stick it in Optimum!**\n",
    "\n",
    "\n",
    "> We can now set up our pipelined execution by specifying which layers to put on each IPU, and passing it to the `parallelize` method that we defined above.\n",
    "\n",
    "> We also call the `.half()` method to cast all the model weights to half-precision (FP16). The `.train()` sets the PyTorch model to training mode.\n",
    "\n",
    "> If you unfamiliar with training in half precision on IPU, then we have a tutorial on [Half and Mixed Precision in Poptorch](https://github.com/graphcore/tutorials/tree/master/tutorials/pytorch/tut3_mixed_precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46eea9",
   "metadata": {},
   "source": [
    "## 3. How `optimum-graphcore` runs models on IPU\n",
    "\n",
    "\n",
    "`optimum-graphcore` will run the model on IPU using both **pipelining** and **data parallelism** in order to maximise hardware use.\n",
    "\n",
    "### Parallelism through pipelining\n",
    "\n",
    "The model layers are split over 8 IPUs. We then use [*pipeline parallelism*](https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/pipelining.html) over the IPUs with gradient accumulation. We subdivide the compute batch into micro-batches that pass through the pipeline in the forward pass and then come back again in the backwards pass, accumulating gradients for the parameters as they go.\n",
    "\n",
    "A complete pipeline step has a ramp-up phase the start and a ramp-down phase at the end. Increasing the gradient accumulation factor, increases the total batch size and also increases the pipeline efficiency, and therefore throughput, because the proportion of time in ramp-up/down phases will be reduced. \n",
    "\n",
    "![pipelining.png](images/pipelining.png)\n",
    "\n",
    "### Partitioning the Model\n",
    "\n",
    "BERT Large has 24 transformer layers, which we will split over our 4 IPUs. The position and word embeddings, and the first 3 encoder layers will sit on IPU0, the following 3 IPUs have 7 transformer layers each. This partition is specified in the `IPUConfig` by the `layers_per_ipu` parameter.\n",
    "\n",
    "<img src=\"https://docs.graphcore.ai/projects/bert-training/en/latest/_images/bert-pipelining.png\" width=\"500\" />\n",
    "\n",
    "### Data Parallelism\n",
    "\n",
    "An IPU-POD16 contains 16 IPUs and our pipeline is 4 IPUs long. We can therefore replicate the pipeline, feeding four different micro-batches to the device, which multiplies the effective mini-batch size by four. We call this configuration a \"4x4 pipeline\".\n",
    "\n",
    "### Recomputation Checkpoints\n",
    "\n",
    "We can make more efficient use of the valuable In-Processor-Memory by saving only selected activation inputs and recomputing the rest. This lets us optimise on memory savings (by not storing all activations) vs FLOP expenditure (by not having to recompute all activations). \n",
    "\n",
    "<img src=\"images/recomputation.png\" width=\"800\" />\n",
    "\n",
    "Source: [TensorFlow Model Parallelism: Recomputation](https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/pipelining.html#recomputation)\n",
    "\n",
    "Checkpoints are automatically placed between each pipeline stage. In addition to these automatic checkpoints, we are adding one at the end of every transformer layer, which leads to better performance.\n",
    "\n",
    "### Replicated Tensor Sharding of Optimizer State\n",
    "\n",
    "As we are using multiple replicas (4 here), we can also distribute our optimizer state to reduce local memory usage, a method called [On-chip Replicated Tensor Sharding (RTS)](https://docs.graphcore.ai/projects/graphcore-glossary/en/latest/index.html#term-Replicated-tensor-sharding).\n",
    "\n",
    "> To further improve memory availability we also have the option to store tensors in the POD-IPU16 Streaming Memory at the cost of increased communications.\n",
    "\n",
    "![rts.png](images/rts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d4a70",
   "metadata": {},
   "source": [
    "## 3. Running with Optimum-Graphcore\n",
    "\n",
    "To use `optimum-graphcore` are three main classes one needs to know:\n",
    "- `IPUTrainer`: the trainer class that takes care of compiling the model to run on IPUs, and of performing training and evaluation.\n",
    "- `IPUTrainingArguments`: the parameters for how the model will be trained by the trainer.\n",
    "- `IPUConfig`: the class that specifies attributes and configuration parameters to compile and put the model on the device.\n",
    "\n",
    "The `IPUTrainer` is very similar to the [ğŸ¤— Transformers Trainer](https://huggingface.co/docs/transformers/main_classes/trainer), and adapting a script using the Trainer to make it work with IPUs will mostly consists of simply swapping the `Trainer` class for the `IPUTrainer` one.\n",
    "\n",
    "The `IPUTrainingArguments` is also very similar to the [ğŸ¤— Transformers TrainingArguments](https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/trainer#transformers.TrainingArguments) with a few extra arguments for IPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06484c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:57.806519Z",
     "iopub.status.busy": "2022-08-09T23:51:57.806312Z",
     "iopub.status.idle": "2022-08-09T23:51:58.058693Z",
     "shell.execute_reply": "2022-08-09T23:51:58.058128Z",
     "shell.execute_reply.started": "2022-08-09T23:51:57.806498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbfce95e8eb4660b9c35f9cd3f2639e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipu_config = IPUConfig.from_pretrained(\"Graphcore/bert-large-ipu\", inference_device_iterations=4, executable_cache_dir = \"/tmp/exe_cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6e31859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:58.060730Z",
     "iopub.status.busy": "2022-08-09T23:51:58.060551Z",
     "iopub.status.idle": "2022-08-09T23:51:58.065412Z",
     "shell.execute_reply": "2022-08-09T23:51:58.064937Z",
     "shell.execute_reply.started": "2022-08-09T23:51:58.060713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPUConfig {\n",
       "  \"decompose_grad_sum\": false,\n",
       "  \"device_iterations\": 1,\n",
       "  \"embedding_serialization_factor\": 2,\n",
       "  \"enable_half_first_order_momentum\": true,\n",
       "  \"enable_half_partials\": true,\n",
       "  \"executable_cache_dir\": \"/tmp/exe_cache/\",\n",
       "  \"execute_encoder_on_cpu_for_generation\": false,\n",
       "  \"gradient_accumulation_steps\": 16,\n",
       "  \"inference_device_iterations\": 4,\n",
       "  \"inference_replication_factor\": {\n",
       "    \"default\": 1,\n",
       "    \"pod16\": 4,\n",
       "    \"pod32\": 8,\n",
       "    \"pod4\": 1,\n",
       "    \"pod64\": 16,\n",
       "    \"pod8\": 2\n",
       "  },\n",
       "  \"ipus_per_replica\": 4,\n",
       "  \"layers_per_ipu\": [\n",
       "    3,\n",
       "    7,\n",
       "    7,\n",
       "    7\n",
       "  ],\n",
       "  \"matmul_proportion\": [\n",
       "    0.15,\n",
       "    0.18,\n",
       "    0.2,\n",
       "    0.25\n",
       "  ],\n",
       "  \"optimizer_state_offchip\": true,\n",
       "  \"optimum_version\": \"1.3.0\",\n",
       "  \"output_mode\": \"final\",\n",
       "  \"profile_dir\": \"\",\n",
       "  \"recompute_checkpoint_every_layer\": true,\n",
       "  \"replicated_tensor_sharding\": true,\n",
       "  \"replication_factor\": {\n",
       "    \"default\": 1,\n",
       "    \"pod16\": 4,\n",
       "    \"pod32\": 8,\n",
       "    \"pod4\": 1,\n",
       "    \"pod64\": 16,\n",
       "    \"pod8\": 2\n",
       "  },\n",
       "  \"seed\": null,\n",
       "  \"sharded_execution_for_inference\": false,\n",
       "  \"transformers_version\": \"4.20.0\",\n",
       "  \"use_popdist\": false\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipu_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5b256",
   "metadata": {},
   "source": [
    "`device_iterations` is the number of batches the device should run before returning to the user. Increasing `device_iterations` can more efficient because the loop runs on the IPU directly, reducing overhead costs. Please see the [documentation](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/batching.html?highlight=device%20iterations#poptorch-options-deviceiterations) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12936f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:58.067591Z",
     "iopub.status.busy": "2022-08-09T23:51:58.067430Z",
     "iopub.status.idle": "2022-08-09T23:51:58.070499Z",
     "shell.execute_reply": "2022-08-09T23:51:58.070005Z",
     "shell.execute_reply.started": "2022-08-09T23:51:58.067575Z"
    }
   },
   "outputs": [],
   "source": [
    "global_batch_size = 256\n",
    "per_device_train_batch_size = 1\n",
    "per_device_eval_batch_size = 2\n",
    "replication_factor = 4\n",
    "gradient_accumulation = int(global_batch_size / per_device_train_batch_size / replication_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9193054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:58.072539Z",
     "iopub.status.busy": "2022-08-09T23:51:58.072378Z",
     "iopub.status.idle": "2022-08-09T23:51:58.076643Z",
     "shell.execute_reply": "2022-08-09T23:51:58.076106Z",
     "shell.execute_reply.started": "2022-08-09T23:51:58.072519Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = IPUTrainingArguments(output_dir=\"/tmp/outputs\",\n",
    "                                     do_train=True,\n",
    "                                     do_eval=True,\n",
    "                                     per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                     per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "                                     gradient_accumulation_steps=gradient_accumulation,\n",
    "                                     learning_rate=2e-4,\n",
    "                                     num_train_epochs=2,\n",
    "                                     logging_steps=25,\n",
    "                                     dataloader_num_workers=32,\n",
    "                                     dataloader_drop_last=True,\n",
    "                                     resume_from_checkpoint=True,\n",
    "                                     pod_type=\"pod16\",\n",
    "                                     save_steps=300,\n",
    "                                     report_to=\"none\",\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a57d24",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d041a185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:58.078721Z",
     "iopub.status.busy": "2022-08-09T23:51:58.078440Z",
     "iopub.status.idle": "2022-08-09T23:51:58.081638Z",
     "shell.execute_reply": "2022-08-09T23:51:58.080665Z",
     "shell.execute_reply.started": "2022-08-09T23:51:58.078704Z"
    }
   },
   "outputs": [],
   "source": [
    "from squad_preprocessing import PadCollate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812e1da",
   "metadata": {},
   "source": [
    "Now we create the `IPUTrainer` from `optimum-graphcore` to train our model on the IPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4abf64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:51:58.084107Z",
     "iopub.status.busy": "2022-08-09T23:51:58.083920Z",
     "iopub.status.idle": "2022-08-09T23:52:03.729749Z",
     "shell.execute_reply": "2022-08-09T23:52:03.728827Z",
     "shell.execute_reply.started": "2022-08-09T23:51:58.084090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding IPU config: gradient_accumulation_steps=64\n",
      "-------------------- Device Allocation --------------------\n",
      "Embedding --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 1\n",
      "Encoder 4  --> IPU 1\n",
      "Encoder 5  --> IPU 1\n",
      "Encoder 6  --> IPU 1\n",
      "Encoder 7  --> IPU 1\n",
      "Encoder 8  --> IPU 1\n",
      "Encoder 9  --> IPU 1\n",
      "Encoder 10 --> IPU 2\n",
      "Encoder 11 --> IPU 2\n",
      "Encoder 12 --> IPU 2\n",
      "Encoder 13 --> IPU 2\n",
      "Encoder 14 --> IPU 2\n",
      "Encoder 15 --> IPU 2\n",
      "Encoder 16 --> IPU 2\n",
      "Encoder 17 --> IPU 3\n",
      "Encoder 18 --> IPU 3\n",
      "Encoder 19 --> IPU 3\n",
      "Encoder 20 --> IPU 3\n",
      "Encoder 21 --> IPU 3\n",
      "Encoder 22 --> IPU 3\n",
      "Encoder 23 --> IPU 3\n",
      "QA Outputs --> IPU 3\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer = IPUTrainer(model=model,\n",
    "                     ipu_config=ipu_config,\n",
    "                     args=training_args, \n",
    "                     train_dataset=train_dataset,\n",
    "                     eval_dataset=validation_features,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Precompiled Executable\n",
    "\n",
    "In order to save time, pre-compiled execution graph can be loaded so the model doesn't get recompiled. In the next steps, your PyTorch source code is compiled into a graph program which dictates how the program can be executed on the IPU hardware if there's no precompiled executable available. \n",
    "\n",
    "You  can see the documentation on [Precompilation and Caching](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/overview.html#precompilation-and-caching) to know how it works.\n",
    "\n",
    "For this example, we have made pre-compiled executables available and will load them into the `exe_cache` folder in order to skip compilation and proceed straight to running your training or evaluation. \n",
    "\n",
    "Note that the VM has limited local storage, your cache directory might also grow large and fill your storage as you recompile so manage your storage accordingly. We recommend changing output paths to `/tmp` so it gets flushed upon shutdown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training executable to skip recompilation. \n",
    "# When present, expect Graph Compilation in the next step to take only a few seconds.\n",
    "!mkdir -p ./exe_cache\n",
    "!ln -s /graphcore/exe_cache/* ./exe_cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, your PyTorch source code is compiled into a graph program which dictates how the program can be executed on the IPU hardware if there's no precompiled executable found. This process can take a few minutes, especially for more complex models.\n",
    "\n",
    "Now you are ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "336f77b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:52:03.732843Z",
     "iopub.status.busy": "2022-08-09T23:52:03.732625Z",
     "iopub.status.idle": "2022-08-10T00:09:58.578624Z",
     "shell.execute_reply": "2022-08-10T00:09:58.577773Z",
     "shell.execute_reply.started": "2022-08-09T23:52:03.732821Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Model...\n",
      "Graph compilation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [07:44<00:00]\n",
      "Compiled/Loaded model in 567.0647092440631 secs\n",
      "***** Running training *****\n",
      "  Num examples = 88524\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Device Iterations = 1\n",
      "  Replication Factor = 4\n",
      "  Gradient Accumulation steps = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Total optimization steps = 690\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c89324758d04b32b4ec2ee5d0127073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1793, 'learning_rate': 0.0001927536231884058, 'epoch': 0.07}\n",
      "{'loss': 1.4808, 'learning_rate': 0.0001855072463768116, 'epoch': 0.14}\n",
      "{'loss': 1.1683, 'learning_rate': 0.0001782608695652174, 'epoch': 0.22}\n",
      "{'loss': 1.0593, 'learning_rate': 0.0001710144927536232, 'epoch': 0.29}\n",
      "{'loss': 0.9102, 'learning_rate': 0.000163768115942029, 'epoch': 0.36}\n",
      "{'loss': 0.9987, 'learning_rate': 0.0001565217391304348, 'epoch': 0.43}\n",
      "{'loss': 0.9337, 'learning_rate': 0.00014927536231884058, 'epoch': 0.51}\n",
      "{'loss': 1.2123, 'learning_rate': 0.00014202898550724638, 'epoch': 0.58}\n",
      "{'loss': 0.9466, 'learning_rate': 0.0001347826086956522, 'epoch': 0.65}\n",
      "{'loss': 1.0442, 'learning_rate': 0.00012753623188405797, 'epoch': 0.72}\n",
      "{'loss': 0.9601, 'learning_rate': 0.00012028985507246378, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/outputs/checkpoint-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8503, 'learning_rate': 0.00011304347826086956, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-------------------- Device Allocation --------------------\n",
      "Embedding --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 1\n",
      "Encoder 4  --> IPU 1\n",
      "Encoder 5  --> IPU 1\n",
      "Encoder 6  --> IPU 1\n",
      "Encoder 7  --> IPU 1\n",
      "Encoder 8  --> IPU 1\n",
      "Encoder 9  --> IPU 1\n",
      "Encoder 10 --> IPU 2\n",
      "Encoder 11 --> IPU 2\n",
      "Encoder 12 --> IPU 2\n",
      "Encoder 13 --> IPU 2\n",
      "Encoder 14 --> IPU 2\n",
      "Encoder 15 --> IPU 2\n",
      "Encoder 16 --> IPU 2\n",
      "Encoder 17 --> IPU 3\n",
      "Encoder 18 --> IPU 3\n",
      "Encoder 19 --> IPU 3\n",
      "Encoder 20 --> IPU 3\n",
      "Encoder 21 --> IPU 3\n",
      "Encoder 22 --> IPU 3\n",
      "Encoder 23 --> IPU 3\n",
      "QA Outputs --> IPU 3\n",
      "-----------------------------------------------------------\n",
      "Configuration saved in /tmp/outputs/checkpoint-300/ipu_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7496, 'learning_rate': 0.00010579710144927538, 'epoch': 0.94}\n",
      "{'loss': 0.8778, 'learning_rate': 9.855072463768117e-05, 'epoch': 1.01}\n",
      "{'loss': 0.6298, 'learning_rate': 9.130434782608696e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7537, 'learning_rate': 8.405797101449276e-05, 'epoch': 1.16}\n",
      "{'loss': 0.5141, 'learning_rate': 7.681159420289855e-05, 'epoch': 1.23}\n",
      "{'loss': 0.5786, 'learning_rate': 6.956521739130436e-05, 'epoch': 1.3}\n",
      "{'loss': 0.5782, 'learning_rate': 6.231884057971015e-05, 'epoch': 1.38}\n",
      "{'loss': 0.577, 'learning_rate': 5.507246376811594e-05, 'epoch': 1.45}\n",
      "{'loss': 0.6481, 'learning_rate': 4.782608695652174e-05, 'epoch': 1.52}\n",
      "{'loss': 0.5955, 'learning_rate': 4.057971014492754e-05, 'epoch': 1.59}\n",
      "{'loss': 0.6576, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/outputs/checkpoint-600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5979, 'learning_rate': 2.608695652173913e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-------------------- Device Allocation --------------------\n",
      "Embedding --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 1\n",
      "Encoder 4  --> IPU 1\n",
      "Encoder 5  --> IPU 1\n",
      "Encoder 6  --> IPU 1\n",
      "Encoder 7  --> IPU 1\n",
      "Encoder 8  --> IPU 1\n",
      "Encoder 9  --> IPU 1\n",
      "Encoder 10 --> IPU 2\n",
      "Encoder 11 --> IPU 2\n",
      "Encoder 12 --> IPU 2\n",
      "Encoder 13 --> IPU 2\n",
      "Encoder 14 --> IPU 2\n",
      "Encoder 15 --> IPU 2\n",
      "Encoder 16 --> IPU 2\n",
      "Encoder 17 --> IPU 3\n",
      "Encoder 18 --> IPU 3\n",
      "Encoder 19 --> IPU 3\n",
      "Encoder 20 --> IPU 3\n",
      "Encoder 21 --> IPU 3\n",
      "Encoder 22 --> IPU 3\n",
      "Encoder 23 --> IPU 3\n",
      "QA Outputs --> IPU 3\n",
      "-----------------------------------------------------------\n",
      "Configuration saved in /tmp/outputs/checkpoint-600/ipu_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7306, 'learning_rate': 1.8840579710144928e-05, 'epoch': 1.81}\n",
      "{'loss': 0.5083, 'learning_rate': 1.1594202898550725e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7656, 'learning_rate': 4.347826086956522e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 488.6573, 'train_samples_per_second': 361.48, 'train_steps_per_second': 1.412, 'train_loss': 0.9048264213230299, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.9048264213230299, metrics={'train_runtime': 488.6573, 'train_samples_per_second': 361.48, 'train_steps_per_second': 1.412, 'train_loss': 0.9048264213230299, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14c2ff",
   "metadata": {},
   "source": [
    "After training, we save the model weights to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9efa9c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:09:58.581233Z",
     "iopub.status.busy": "2022-08-10T00:09:58.581057Z",
     "iopub.status.idle": "2022-08-10T00:09:59.276586Z",
     "shell.execute_reply": "2022-08-10T00:09:59.275930Z",
     "shell.execute_reply.started": "2022-08-10T00:09:58.581216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/outputs\n",
      "-------------------- Device Allocation --------------------\n",
      "Embedding --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 1\n",
      "Encoder 4  --> IPU 1\n",
      "Encoder 5  --> IPU 1\n",
      "Encoder 6  --> IPU 1\n",
      "Encoder 7  --> IPU 1\n",
      "Encoder 8  --> IPU 1\n",
      "Encoder 9  --> IPU 1\n",
      "Encoder 10 --> IPU 2\n",
      "Encoder 11 --> IPU 2\n",
      "Encoder 12 --> IPU 2\n",
      "Encoder 13 --> IPU 2\n",
      "Encoder 14 --> IPU 2\n",
      "Encoder 15 --> IPU 2\n",
      "Encoder 16 --> IPU 2\n",
      "Encoder 17 --> IPU 3\n",
      "Encoder 18 --> IPU 3\n",
      "Encoder 19 --> IPU 3\n",
      "Encoder 20 --> IPU 3\n",
      "Encoder 21 --> IPU 3\n",
      "Encoder 22 --> IPU 3\n",
      "Encoder 23 --> IPU 3\n",
      "QA Outputs --> IPU 3\n",
      "-----------------------------------------------------------\n",
      "Configuration saved in /tmp/outputs/ipu_config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7359abf",
   "metadata": {},
   "source": [
    "## 5. Validation\n",
    "\n",
    "We will now take the model we just trained on the training data and run validation on the SQuAD validation dataset. The model will run on a 4-IPU pipeline that we will replicate 4 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44bdee",
   "metadata": {},
   "source": [
    "We loop over all the validation data examples and get the `raw_predictions` for the start and end positions of where the answer to the question lies in the text passage for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d11df40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:09:59.279150Z",
     "iopub.status.busy": "2022-08-10T00:09:59.278964Z",
     "iopub.status.idle": "2022-08-10T00:12:58.513096Z",
     "shell.execute_reply": "2022-08-10T00:12:58.512029Z",
     "shell.execute_reply.started": "2022-08-10T00:09:59.279131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `PoptorchPipelinedBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "Compiling Model...\n",
      "Graph compilation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:47<00:00]\n",
      "Compiled/Loaded model in 160.53022746089846 secs\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10784\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712eda4b55c4426cb25d2fb98bdeee60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_output = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc99abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:12:58.515673Z",
     "iopub.status.busy": "2022-08-10T00:12:58.515504Z",
     "iopub.status.idle": "2022-08-10T00:12:58.518602Z",
     "shell.execute_reply": "2022-08-10T00:12:58.518034Z",
     "shell.execute_reply.started": "2022-08-10T00:12:58.515655Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from squad_preprocessing import postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24948756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:12:58.521068Z",
     "iopub.status.busy": "2022-08-10T00:12:58.520894Z",
     "iopub.status.idle": "2022-08-10T00:12:58.561244Z",
     "shell.execute_reply": "2022-08-10T00:12:58.560251Z",
     "shell.execute_reply.started": "2022-08-10T00:12:58.521051Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_predictions = []\n",
    "raw_predictions.append(eval_output.predictions[0].astype(float))\n",
    "raw_predictions.append(eval_output.predictions[1].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3addecf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:12:58.563960Z",
     "iopub.status.busy": "2022-08-10T00:12:58.563788Z",
     "iopub.status.idle": "2022-08-10T00:12:58.567923Z",
     "shell.execute_reply": "2022-08-10T00:12:58.567264Z",
     "shell.execute_reply.started": "2022-08-10T00:12:58.563943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10784, 384)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867850e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:12:58.570179Z",
     "iopub.status.busy": "2022-08-10T00:12:58.570009Z",
     "iopub.status.idle": "2022-08-10T00:12:58.573642Z",
     "shell.execute_reply": "2022-08-10T00:12:58.573056Z",
     "shell.execute_reply.started": "2022-08-10T00:12:58.570163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
       "    num_rows: 10784\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9b7a3",
   "metadata": {},
   "source": [
    "We now post-process the raw predictions to the question answering task to get the best prediction that's valid for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab0fde6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:12:58.575865Z",
     "iopub.status.busy": "2022-08-10T00:12:58.575702Z",
     "iopub.status.idle": "2022-08-10T00:13:38.332922Z",
     "shell.execute_reply": "2022-08-10T00:13:38.332124Z",
     "shell.execute_reply.started": "2022-08-10T00:12:58.575849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 10570 example predictions split into 10784 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee98e7b8f5042efa9bdf92582ebb818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"],\n",
    "                                               validation_features,\n",
    "                                               raw_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4193f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:38.335589Z",
     "iopub.status.busy": "2022-08-10T00:13:38.335407Z",
     "iopub.status.idle": "2022-08-10T00:13:41.521266Z",
     "shell.execute_reply": "2022-08-10T00:13:41.520132Z",
     "shell.execute_reply.started": "2022-08-10T00:13:38.335570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0924a542a66c4260bbfd95cb6a2e8879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3cac302bc44bea82b895a67eb39ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 84.5127719962157, 'f1': 91.06852496947944}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "formatted_predictions = [{\"id\": k, \"prediction_text\": v}\n",
    "                         for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]}\n",
    "              for ex in datasets[\"validation\"]]\n",
    "metrics = metric.compute(predictions=formatted_predictions, references=references)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9b39d",
   "metadata": {},
   "source": [
    "We obtain here a good validation score for SQuADv1.\n",
    "\n",
    "| BERT-Large                             | Exact Match | F1 Score |\n",
    "|----------------------------------------|:-----------:|:--------:|\n",
    "| Reference (Devling et al. 2018)        | 84.1        | 90.9     |\n",
    "| IPU-POD16 with IPU pre-trained weights | 84.5        | 91.0     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dba3b4",
   "metadata": {},
   "source": [
    "## 6. Inference\n",
    "\n",
    "We can now use our fine-tuned model to answer questions. Let's start by defining a task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83d30fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:41.523897Z",
     "iopub.status.busy": "2022-08-10T00:13:41.523703Z",
     "iopub.status.idle": "2022-08-10T00:13:41.526854Z",
     "shell.execute_reply": "2022-08-10T00:13:41.526282Z",
     "shell.execute_reply.started": "2022-08-10T00:13:41.523879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define task\n",
    "question = \"What speed-up can one expect from using sequence packing for training BERT on IPU?\"\n",
    "answer_text = \"We find that at sequence length 512 padding tokens represent in excess of 50% of the Wikipedia\" \\\n",
    "              \"dataset used for pretraining BERT (Bidirectional Encoder Representations from Transformers).\" \\\n",
    "             \"Therefore by removing all padding we achieve a 2x speed-up in terms of sequences/sec.\" \\\n",
    "             \"To exploit this characteristic of the dataset,\" \\\n",
    "             \"we develop and contrast two deterministic packing algorithms.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833efdcd",
   "metadata": {},
   "source": [
    "Let's get the model inputs ready and create our model. We'll import the weights from the pre-trained, fine-tuned BERT model from the previous sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "961bb39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:41.529316Z",
     "iopub.status.busy": "2022-08-10T00:13:41.529142Z",
     "iopub.status.idle": "2022-08-10T00:13:43.729375Z",
     "shell.execute_reply": "2022-08-10T00:13:43.728559Z",
     "shell.execute_reply.started": "2022-08-10T00:13:41.529301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "input_encoding = tokenizer.encode_plus((question, answer_text))\n",
    "\n",
    "# Extract inputs, add batch dimension\n",
    "input_tensor = torch.tensor(input_encoding[\"input_ids\"]).unsqueeze(0)\n",
    "attention_tensor= torch.tensor(input_encoding[\"attention_mask\"]).unsqueeze(0)\n",
    "token_types=torch.tensor(input_encoding[\"token_type_ids\"]).unsqueeze(0)\n",
    "    \n",
    "# Get model and load the fine-tuned weights\n",
    "model = transformers.BertForQuestionAnswering.from_pretrained(\"/tmp/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c40b5",
   "metadata": {},
   "source": [
    "Optionally, instead of using the fine-tuned weights we saved in the previous section, you can download fine-tuned weights from the [Graphcore organisation on the HuggingFace Model Hub](https://huggingface.co/Graphcore). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfc678bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:43.731891Z",
     "iopub.status.busy": "2022-08-10T00:13:43.731630Z",
     "iopub.status.idle": "2022-08-10T00:13:43.736172Z",
     "shell.execute_reply": "2022-08-10T00:13:43.734950Z",
     "shell.execute_reply.started": "2022-08-10T00:13:43.731872Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = transformers.BertForQuestionAnswering.from_pretrained(\"Graphcore/bert-large-uncased-squad11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26ae76",
   "metadata": {},
   "source": [
    "We can now solve the task and print the answer to the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69901089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:43.738733Z",
     "iopub.status.busy": "2022-08-10T00:13:43.738569Z",
     "iopub.status.idle": "2022-08-10T00:13:44.166186Z",
     "shell.execute_reply": "2022-08-10T00:13:44.165151Z",
     "shell.execute_reply.started": "2022-08-10T00:13:43.738718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What speed-up can one expect from using sequence packing for training BERT on IPU?\n",
      "Answer: 2x\n"
     ]
    }
   ],
   "source": [
    "# Solve task\n",
    "outputs = model(input_tensor, attention_tensor, token_types)\n",
    "\n",
    "# Extract answer\n",
    "answer_start, answer_stop = outputs.start_logits.argmax(), outputs.end_logits.argmax()\n",
    "answer_ids = input_tensor.squeeze()[answer_start:answer_stop + 1]\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids, skip_special_tokens=True)\n",
    "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "# Print results\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49961906",
   "metadata": {},
   "source": [
    "## 7. Uploading to HuggingFace Model Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc6d47",
   "metadata": {},
   "source": [
    "We can share our model to HuggingFace Model Hub and leverage HuggingFace inference API for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea7921a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:44.169414Z",
     "iopub.status.busy": "2022-08-10T00:13:44.169224Z",
     "iopub.status.idle": "2022-08-10T00:13:44.172339Z",
     "shell.execute_reply": "2022-08-10T00:13:44.171788Z",
     "shell.execute_reply.started": "2022-08-10T00:13:44.169395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure you have git-lfs and huggingface-hub\n",
    "# !apt-get update && apt-get upgrade -y && apt-get install -y git git-lfs \n",
    "# !pip install -y huggingface-hub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461996db",
   "metadata": {},
   "source": [
    "You would need to login to your HuggingFace account and get your token. Running `notebook_login()` will launch an interactive cell and link to your HuggingFace token page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8793ce79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:44.175178Z",
     "iopub.status.busy": "2022-08-10T00:13:44.174906Z",
     "iopub.status.idle": "2022-08-10T00:13:44.200980Z",
     "shell.execute_reply": "2022-08-10T00:13:44.200090Z",
     "shell.execute_reply.started": "2022-08-10T00:13:44.175161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9705bac7802d4b868356454f539efbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57e47822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T00:13:44.203551Z",
     "iopub.status.busy": "2022-08-10T00:13:44.203385Z",
     "iopub.status.idle": "2022-08-10T00:13:44.358716Z",
     "shell.execute_reply": "2022-08-10T00:13:44.345781Z",
     "shell.execute_reply.started": "2022-08-10T00:13:44.203533Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must login to the Hugging Face hub on this computer by typing `transformers-cli login` and entering your credentials to use `use_auth_token=True`. Alternatively, you can pass your own token as the `use_auth_token` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-bcd2fd7832f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Upload the checkpoint to HuggingFace Model Hub.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<hf-username>/Optimum-Graphcore-Demo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<hf-username>/Optimum-Graphcore-Demo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_path_or_name, repo_url, use_temp_dir, commit_message, organization, private, use_auth_token, max_shard_size, **model_card_kwargs)\u001b[0m\n\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;31m# Create or clone the repo. If the repo is already cloned, this just retrieves the path to the repo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2668\u001b[0;31m         repo = self._create_or_get_repo(\n\u001b[0m\u001b[1;32m   2669\u001b[0m             \u001b[0mrepo_path_or_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_path_or_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_create_or_get_repo\u001b[0;34m(cls, repo_path_or_name, repo_url, organization, private, use_auth_token)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrepo_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path_or_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0mrepo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path_or_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             repo_url = cls._get_repo_url_from_name(\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_repo_url_from_name\u001b[0;34m(repo_name, organization, private, use_auth_token)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    970\u001b[0m                     \u001b[0;34m\"You must login to the Hugging Face hub on this computer by typing `transformers-cli login` and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0;34m\"entering your credentials to use `use_auth_token=True`. Alternatively, you can pass your own \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You must login to the Hugging Face hub on this computer by typing `transformers-cli login` and entering your credentials to use `use_auth_token=True`. Alternatively, you can pass your own token as the `use_auth_token` argument."
     ]
    }
   ],
   "source": [
    "# Upload the checkpoint to HuggingFace Model Hub.\n",
    "# model.push_to_hub(\"<hf-username>/Optimum-Graphcore-Demo\")\n",
    "# tokenizer.push_to_hub(\"<hf-username>/Optimum-Graphcore-Demo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "008a66177cbc400587af50b64b22c8e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "00928119156c47b7b0651dd77a3b703d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "01143a3b887c456cb5ba6a5554fa1781": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0181aea86cf2426a8df2ef59eb006163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "01ee47b5825f44b9a35b0f1a2d5f786d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0481fce1711a42419aaf7ceb6347ed9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9aa7e4a5d1bd44d28212358850a77f5b",
        "IPY_MODEL_2a2f4dde3e41485d98ae5142ecee12c9"
       ],
       "layout": "IPY_MODEL_5c8791000e03443fa70dec071b9db398"
      }
     },
     "066fa664116849098018e9baa066417d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_f262cd7b1a3c40bbbad84197e64de588",
       "max": 346,
       "style": "IPY_MODEL_9ab28f98f30e440aa49206cacace1931",
       "value": 86
      }
     },
     "07779d5402db4cf48b9f78b275ae8ef0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "07c9aed3f6ba41b4b17ea0f6e86477e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0808d61da7ab444288336a14f34d5bc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9a3803c989da4009ad588ca1283cf70e",
       "style": "IPY_MODEL_c681ea503e094c149100da1cbf572358",
       "value": " 3/3 [10:40&lt;00:00, 213.47s/it]"
      }
     },
     "0872f45312754a6dbe556f9bdac4d8f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "0920a4e34496461681c9376f086a4f02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b13343e39544e9881cf2e26f5ffba3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b8bfb3536424f1c8093ad658dd2349c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "0e89f27f9ade48b9876e365e8dc8de42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3b7a4b71108b4abdbc455be2b956b575",
        "IPY_MODEL_1c3a111026ef43c4a751de7bb0cf6b63",
        "IPY_MODEL_e1e5b2d4470c49478b1de0f8b8d512a4"
       ],
       "layout": "IPY_MODEL_fe16a84150d94088a7748459d74e7a57"
      }
     },
     "0f3d414b44974449b24c07cddd248e13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "1261d257152a40a18368f595466aac1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 2 - Step: 345 - Loss: 0.380 - Throughput: 556.949 seq/s: 100%",
       "layout": "IPY_MODEL_fce00d252d75456b9199a4313faf0963",
       "max": 346,
       "style": "IPY_MODEL_0f3d414b44974449b24c07cddd248e13",
       "value": 346
      }
     },
     "1344574ddf854e83a8f85ff6c1b69251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_419c4e1e232d4b6b89d2e9edb83a3fc7",
       "style": "IPY_MODEL_f4666e5976f847538a3eb3de5de251dd",
       "value": " 86/346 [00:46&lt;02:17,  1.89it/s]"
      }
     },
     "14207f0293e741eaa1153902e55fb2e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a0330f3dd67346d0ad29977b1c930c5c",
       "max": 346,
       "style": "IPY_MODEL_72db2eeaaf7f4469898b0d345f125a1a",
       "value": 346
      }
     },
     "1434848ba8e34924a81900027b727f3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e6cdeccedbeb4ddca7cab4f0658850d0",
       "max": 346,
       "style": "IPY_MODEL_7bb5161067c440d6ab72ae1095b71407",
       "value": 346
      }
     },
     "14adb7851e6f49a0a5692bbb67365c9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "175769e2baa448fe9e1d0a6d0cd21f96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4613b1f9f4c4682ad7dd0bd99b64ccc",
       "style": "IPY_MODEL_cca7d495a9e24bcc9e2818500e465b91",
       "value": " 346/346 [07:23&lt;00:00,  1.28s/it]"
      }
     },
     "17831a84adfd4a3facbf706ef22f7316": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "17e50d4efe934e978da14755e29a6127": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18535685b6b3480393a392e5c004582b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_568c40a5d1ef47f6864f19d915ec20e0",
        "IPY_MODEL_7ed2a2aab41e4acd9dd1e3b3fa3731b4",
        "IPY_MODEL_6b359900df9a4c278ce08a408aa511cf"
       ],
       "layout": "IPY_MODEL_6dba9e1af5c44890b8b7d86130197d9a"
      }
     },
     "1c3a111026ef43c4a751de7bb0cf6b63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6e0e5239bdd64b6daf4f4e21162dfc3d",
       "max": 2,
       "style": "IPY_MODEL_51a1eb91ba6047138e3635987fd00f45",
       "value": 2
      }
     },
     "1d4ec2582038466b9c8b3c273b9b8f1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1d7981b404744ba4b791c98922818cd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1f111acf18bf4dc4a9728746be834514": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6306d37f90f845fdab4a15ac205627e0",
       "max": 10570,
       "style": "IPY_MODEL_86d9f694d52d4b6b89ba9aebe142d77c",
       "value": 10570
      }
     },
     "2353d9e0a42c42e8a1c8fef1f137aca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9a8efa64777841fa9a312d45fbe91ff1",
        "IPY_MODEL_0808d61da7ab444288336a14f34d5bc0"
       ],
       "layout": "IPY_MODEL_bb2ef00251204bddaaecac5555b9e81f"
      }
     },
     "2380d82578cc45a5ba4cf481f59354fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24d0269086554bc7a14231dd7d03481a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "25edc3cac1fd427db24c82a0693cf7a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2669b96b18ab46a2a5e0736fef3d5f91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d660db84f39b4ca693057292e4d6e2a8",
       "style": "IPY_MODEL_5878ce9ce7124591b8935390d0b6968e",
       "value": " 346/346 [03:20&lt;00:00,  1.73it/s]"
      }
     },
     "269f1e466dcc41afa319def078b1045f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "29d8efdddad049f2b815f0e4e7a3bbaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2a2f4dde3e41485d98ae5142ecee12c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2b1e2a04955541e1ae33736b01b7c8c3",
       "style": "IPY_MODEL_aee35c3dde87426aaee859d7dab30775",
       "value": " 113/113 [04:58&lt;00:00,  2.64s/it]"
      }
     },
     "2b1e2a04955541e1ae33736b01b7c8c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2d7b09ef38c74d1484db4147a543a3b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d582c554820a44918b0cd2fa8009bce2",
       "max": 3,
       "style": "IPY_MODEL_63cc107be8f44e279c4299b7d17b4ffb",
       "value": 3
      }
     },
     "32bfe2d3c6fd4bc6b7c1ecc8b9f754d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b1ff12dbafba44d792d197a66f9741b7",
       "style": "IPY_MODEL_50611ea36f7842ca9dd42476ba0e768b",
       "value": " 346/346 [04:07&lt;00:00,  1.40it/s]"
      }
     },
     "32efc833332242d2b9bdc5732f3f83e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5abaedd8a0df4c5b93e37e1e1c4015fb",
       "style": "IPY_MODEL_d660f1b593e74ac695623b27234cfd14",
       "value": "Epoch: 1 - Step: 345 - Loss: 0.609 - Throughput: 631.668 seq/s: 100%"
      }
     },
     "3515d1d1982240f792fa7f4b8c9a4bca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37954b48eb164ffe8053637d740ec665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c7f5d6085c264e66aca41b2941d66c08",
       "style": "IPY_MODEL_caa86e7c770c4b65979cb298694ecc3c",
       "value": "Epoch: 0 - Step: 85 - Loss: 1.309 - Throughput: 631.741 seq/s:  25%"
      }
     },
     "37efcdb2a015414397f9d7551c31bd69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_43e083c3b8214747ae10324e2b29ef12",
       "style": "IPY_MODEL_dfe6bcd0588846ed980238cce0ce3f23",
       "value": "100%"
      }
     },
     "394806f1ef1549019f5e98749e4942c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "3b7a4b71108b4abdbc455be2b956b575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a416cc948ae445088d67e79fdef5de7f",
       "style": "IPY_MODEL_7abf963c624e403bb0db7464d1622555",
       "value": "100%"
      }
     },
     "3c65035318444b85bf2ca4602daec6b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3daf6e67d09444c8bb0dc4f6383431d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c8b69b41ac3946d49f9ded898ac17637",
        "IPY_MODEL_ef0f5be231f94dbeba93712230d0ad87"
       ],
       "layout": "IPY_MODEL_77f2d799553347bdb5d7977a2a870f24"
      }
     },
     "3e4f986cad4244f195cac0ce9a86f761": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3f50e999fa794c6fbdc6b4911051d16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3faac7495c4c467da776fbf856c4618b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c440a5eef70547fdbdd428f07aa3ee68",
       "style": "IPY_MODEL_8e18e492dae0467cb9ebc44757c91fd6",
       "value": " 3/3 [09:31&lt;00:00, 189.92s/it]"
      }
     },
     "419c4e1e232d4b6b89d2e9edb83a3fc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "424fd49e58684ddf81b01383c45c2c35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c701f026d5cb415c90f45b15a19f8b0d",
        "IPY_MODEL_51fd1ad896b5445486cc114348bdccbf"
       ],
       "layout": "IPY_MODEL_83ab52267b0c45ed97ef1115182cd8c4"
      }
     },
     "43235a59a1f04f3b919ddfa67b993ec1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a6fd50dcdd8c4b3b99acb647debbf585",
        "IPY_MODEL_f03846bf22224128a81aaf092477426f"
       ],
       "layout": "IPY_MODEL_0b13343e39544e9881cf2e26f5ffba3c"
      }
     },
     "43431bea444146bc9612c4baa0464363": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a146b51061ae45ba9a99eb5149313a22",
        "IPY_MODEL_4a828a817d264c7dbd6ca1ffbea8b149"
       ],
       "layout": "IPY_MODEL_01143a3b887c456cb5ba6a5554fa1781"
      }
     },
     "43e083c3b8214747ae10324e2b29ef12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "449028d1c04c44f29d97b7291d88336a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "454af4b9e64b415a987450c467273256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "45bd07013d0148f1919d350b8794b383": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "483e09719495454eb0f9554d42772516": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_63fb867af23946af9f2ff7887197f4df",
        "IPY_MODEL_53e5ba5bba5c451c93d47af31d56bed0"
       ],
       "layout": "IPY_MODEL_07c9aed3f6ba41b4b17ea0f6e86477e5"
      }
     },
     "4892ddbb6757414fba7450c4d2895183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "4a828a817d264c7dbd6ca1ffbea8b149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_17e50d4efe934e978da14755e29a6127",
       "style": "IPY_MODEL_cc9f73329ad44784936f9e39175e2762",
       "value": " 346/346 [05:06&lt;00:00,  1.13it/s]"
      }
     },
     "4f41a49093244e499f19edd0b4ce07b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4fffcf0014b243e389a16493818ae436": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "50611ea36f7842ca9dd42476ba0e768b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "519cd5a0c1b744ca82150c05427aa678": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "51a1eb91ba6047138e3635987fd00f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "51fd1ad896b5445486cc114348bdccbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7629aaac2c0e402a9a6f85bb698ee85b",
       "style": "IPY_MODEL_5e90c8d3f1d7464f96d52b62093c742d",
       "value": " 10570/10570 [00:22&lt;00:00, 480.14it/s]"
      }
     },
     "5229f392494d4a8190aece85619fa3c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "53e5ba5bba5c451c93d47af31d56bed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8f0558c88cfe40dbb463a84ad1ce2f3b",
       "style": "IPY_MODEL_008a66177cbc400587af50b64b22c8e4",
       "value": " 10570/10570 [00:22&lt;00:00, 473.43it/s]"
      }
     },
     "56545676fdee435a9862ac1da85e0618": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bd184564c54d475bb65c7cc429f284d4",
       "style": "IPY_MODEL_6db795a8ad43439e874755e4ea93fea7",
       "value": "Epochs:   0%"
      }
     },
     "5688c41f7eaf437081e532ba6c98d6eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_66e4b0e39fd940d586bc6cb05467dd5f",
       "max": 113,
       "style": "IPY_MODEL_1d4ec2582038466b9c8b3c273b9b8f1e",
       "value": 113
      }
     },
     "568c40a5d1ef47f6864f19d915ec20e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b3fdedd4fa4d42ccb734e5476b46f461",
       "style": "IPY_MODEL_00928119156c47b7b0651dd77a3b703d",
       "value": "Epoch: 2 - Step: 345 - Loss: 0.353 - Throughput: 571.998 seq/s: 100%"
      }
     },
     "573939d58d194a30b18ff15aed870bec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "57ced115d7474cd5b2bc902eb5d61f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5878ce9ce7124591b8935390d0b6968e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5abaedd8a0df4c5b93e37e1e1c4015fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c8791000e03443fa70dec071b9db398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e90c8d3f1d7464f96d52b62093c742d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6306d37f90f845fdab4a15ac205627e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "632e54ed92974d278c2e9200c8a630f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_acffceb0aa434c169979520f44582137",
        "IPY_MODEL_2d7b09ef38c74d1484db4147a543a3b2",
        "IPY_MODEL_3faac7495c4c467da776fbf856c4618b"
       ],
       "layout": "IPY_MODEL_a35d9b8305bb40a2a8a90f7e32bae8d8"
      }
     },
     "63cc107be8f44e279c4299b7d17b4ffb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "63fb867af23946af9f2ff7887197f4df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_86b64788c81042079a204561c008ce26",
       "max": 10570,
       "style": "IPY_MODEL_269f1e466dcc41afa319def078b1045f",
       "value": 10570
      }
     },
     "66e4b0e39fd940d586bc6cb05467dd5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6748f83e2145488bbd3e62e5beba7511": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "687c78cdd0e445389d54faea359c4ff3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_01ee47b5825f44b9a35b0f1a2d5f786d",
       "style": "IPY_MODEL_a2ceecf934a648858b7e86f5d0ca1548",
       "value": " 113/113 [02:57&lt;00:00,  1.57s/it]"
      }
     },
     "6a55285da8ba42a5b42433a9641f9688": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b72f3358acb34d979d11623b3407e5b3",
       "style": "IPY_MODEL_8efb053df531477da4af56ff6de17e33",
       "value": "Step: 112 - throughput: 3287.240 samples/s: 100%"
      }
     },
     "6b359900df9a4c278ce08a408aa511cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cf662aa184e043cb9616489a749f9d41",
       "style": "IPY_MODEL_25edc3cac1fd427db24c82a0693cf7a7",
       "value": " 346/346 [03:07&lt;00:00,  1.75it/s]"
      }
     },
     "6b5bc74901b34b15ae9b91bccd5f707d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a11cc6f332ee425f889b83dc4d47ddf4",
       "style": "IPY_MODEL_17831a84adfd4a3facbf706ef22f7316",
       "value": " 346/346 [03:12&lt;00:00,  1.91it/s]"
      }
     },
     "6db795a8ad43439e874755e4ea93fea7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6dba9e1af5c44890b8b7d86130197d9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e0e5239bdd64b6daf4f4e21162dfc3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6fb85aeae69f490da819efd2624435d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7269ab27965a4204a63d42dc3bc659ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "72db2eeaaf7f4469898b0d345f125a1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "731d640ba4444bd49b786b907eb37ad4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "74fe05961b97400588a29f7322e2db81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7629aaac2c0e402a9a6f85bb698ee85b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "76537c65be544568b91176fe115fdf4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "765e2d80436446dd9c3bbc1e68a7923e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ef246036865e45c3ba3637dc1ebbe561",
       "max": 2,
       "style": "IPY_MODEL_07779d5402db4cf48b9f78b275ae8ef0",
       "value": 2
      }
     },
     "76d1147989b0470c888d003311de0685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "77f2d799553347bdb5d7977a2a870f24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7abf963c624e403bb0db7464d1622555": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7b6c6d3d77474913b0edc9f4db18f92b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7bb5161067c440d6ab72ae1095b71407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7ed2a2aab41e4acd9dd1e3b3fa3731b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_731d640ba4444bd49b786b907eb37ad4",
       "max": 346,
       "style": "IPY_MODEL_454af4b9e64b415a987450c467273256",
       "value": 346
      }
     },
     "83ab52267b0c45ed97ef1115182cd8c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8521a42dc4ea4a6998612bf0193b9ecc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_94c8d3393a8446919ebf351340bacabb",
        "IPY_MODEL_2669b96b18ab46a2a5e0736fef3d5f91"
       ],
       "layout": "IPY_MODEL_45bd07013d0148f1919d350b8794b383"
      }
     },
     "86b64788c81042079a204561c008ce26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "86d9f694d52d4b6b89ba9aebe142d77c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "88bad03b52904e7285df98b1f90268b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8bb6baf370674ce4aa7bd827e01eec43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_449028d1c04c44f29d97b7291d88336a",
       "style": "IPY_MODEL_ecdf7f81055c4e15ba236473d045f570",
       "value": " 2/2 [00:00&lt;00:00, 113.76it/s]"
      }
     },
     "8e18e492dae0467cb9ebc44757c91fd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8ea22108461f4b14a0604b3998a15d2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8efb053df531477da4af56ff6de17e33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8f0558c88cfe40dbb463a84ad1ce2f3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91c171a6bb0946b48a1e318a546671d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92f001bc0f8f4699b5b5ab32c5726d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c38574303a314857af145c9314ce9f70",
        "IPY_MODEL_687c78cdd0e445389d54faea359c4ff3"
       ],
       "layout": "IPY_MODEL_b9e96a1b01da4c4ea96d325506b5a191"
      }
     },
     "94c8d3393a8446919ebf351340bacabb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 2 - Step: 345 - Loss: 0.354 - Throughput: 589.261 seq/s: 100%",
       "layout": "IPY_MODEL_ee8982c161d248d2b03cd7e64d09dcf6",
       "max": 346,
       "style": "IPY_MODEL_c19d37afbe1245d0b7eeded45c3dc8ba",
       "value": 346
      }
     },
     "9a3803c989da4009ad588ca1283cf70e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a64ac9a4c324ae789053bfbdac23803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_519cd5a0c1b744ca82150c05427aa678",
       "style": "IPY_MODEL_a2cc96a7f2be4924b4eb3f2c5ca441b3",
       "value": " 0/3 [00:46&lt;?, ?it/s]"
      }
     },
     "9a8efa64777841fa9a312d45fbe91ff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epochs: 100%",
       "layout": "IPY_MODEL_6748f83e2145488bbd3e62e5beba7511",
       "max": 3,
       "style": "IPY_MODEL_af1ce28acb6a4508834c321dc27345d3",
       "value": 3
      }
     },
     "9aa7e4a5d1bd44d28212358850a77f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Step: 112 - throughput: 3199.077 samples/s: 100%",
       "layout": "IPY_MODEL_5229f392494d4a8190aece85619fa3c9",
       "max": 113,
       "style": "IPY_MODEL_f5f7d6d815b64646bd467d53bed0365c",
       "value": 113
      }
     },
     "9ab28f98f30e440aa49206cacace1931": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9bfe384fbb324c5b98c58186e69eddb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c99a5d9125da4d7a80e14059376f754b",
        "IPY_MODEL_175769e2baa448fe9e1d0a6d0cd21f96"
       ],
       "layout": "IPY_MODEL_29d8efdddad049f2b815f0e4e7a3bbaa"
      }
     },
     "9cd8f1fd9295475fb7f0f8c72b88d39a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bded3a538b6440d78dd6a0b8700ae561",
        "IPY_MODEL_14207f0293e741eaa1153902e55fb2e6",
        "IPY_MODEL_ccd71a510a9949659751a3620d296894"
       ],
       "layout": "IPY_MODEL_74fe05961b97400588a29f7322e2db81"
      }
     },
     "a0330f3dd67346d0ad29977b1c930c5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a11cc6f332ee425f889b83dc4d47ddf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a146b51061ae45ba9a99eb5149313a22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 0 - Step: 345 - Loss: 0.791 - Throughput: 602.960 seq/s: 100%",
       "layout": "IPY_MODEL_91c171a6bb0946b48a1e318a546671d9",
       "max": 346,
       "style": "IPY_MODEL_e4b2f87a8b01461a8cf6478cc98091d2",
       "value": 346
      }
     },
     "a2cc96a7f2be4924b4eb3f2c5ca441b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a2ceecf934a648858b7e86f5d0ca1548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a35d9b8305bb40a2a8a90f7e32bae8d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a416cc948ae445088d67e79fdef5de7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a53b252f9ec04ebfac3ac8de73610a31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a575a994ef5a4b9998bc540532de6473": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_56545676fdee435a9862ac1da85e0618",
        "IPY_MODEL_c027c549f513403a8dd0e39497b0c3cc",
        "IPY_MODEL_9a64ac9a4c324ae789053bfbdac23803"
       ],
       "layout": "IPY_MODEL_aa45bce80ba04b66b99c79249bf05c0b"
      }
     },
     "a5b48da86e624d08b6b37d37ec2938b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_32efc833332242d2b9bdc5732f3f83e2",
        "IPY_MODEL_1434848ba8e34924a81900027b727f3f",
        "IPY_MODEL_6b5bc74901b34b15ae9b91bccd5f707d"
       ],
       "layout": "IPY_MODEL_0181aea86cf2426a8df2ef59eb006163"
      }
     },
     "a6fd50dcdd8c4b3b99acb647debbf585": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 1 - Step: 345 - Loss: 0.701 - Throughput: 576.474 seq/s: 100%",
       "layout": "IPY_MODEL_0920a4e34496461681c9376f086a4f02",
       "max": 346,
       "style": "IPY_MODEL_76d1147989b0470c888d003311de0685",
       "value": 346
      }
     },
     "a833ce9bfc554ef7ae2c462e896b1e47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa45bce80ba04b66b99c79249bf05c0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "acffceb0aa434c169979520f44582137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a53b252f9ec04ebfac3ac8de73610a31",
       "style": "IPY_MODEL_14adb7851e6f49a0a5692bbb67365c9b",
       "value": "Epochs: 100%"
      }
     },
     "ad16ce91257f44eb8628fbac9eade9da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epochs: 100%",
       "layout": "IPY_MODEL_d174c9c67fec40f0bed694784a211a09",
       "max": 3,
       "style": "IPY_MODEL_0872f45312754a6dbe556f9bdac4d8f4",
       "value": 3
      }
     },
     "aee35c3dde87426aaee859d7dab30775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "af1ce28acb6a4508834c321dc27345d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b1ff12dbafba44d792d197a66f9741b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b3fdedd4fa4d42ccb734e5476b46f461": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b4fd01884fde493999a6d2a7be7a9140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ad16ce91257f44eb8628fbac9eade9da",
        "IPY_MODEL_ff9adb8c41ce4e97bf8245f9dab30430"
       ],
       "layout": "IPY_MODEL_ec1436ebadf94df9a952badc66d9e51d"
      }
     },
     "b72f3358acb34d979d11623b3407e5b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9e96a1b01da4c4ea96d325506b5a191": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb2ef00251204bddaaecac5555b9e81f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb3aa322a3fb4027ac477afb4e12a637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e47ee37994894906a0c9ca66c6917a5c",
       "style": "IPY_MODEL_cc53dd8973d9476d85280ce0e40bfbfa",
       "value": "100%"
      }
     },
     "bbcc0cb21037499b8e8a4b7adf0b38e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efc5029196ca434b869a31ae9c239b57",
       "style": "IPY_MODEL_88bad03b52904e7285df98b1f90268b3",
       "value": " 113/113 [02:25&lt;00:00,  9.70it/s]"
      }
     },
     "bc08f9d70ff948d5a43998903a474237": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd184564c54d475bb65c7cc429f284d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bded3a538b6440d78dd6a0b8700ae561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8ea22108461f4b14a0604b3998a15d2b",
       "style": "IPY_MODEL_3c65035318444b85bf2ca4602daec6b2",
       "value": "Epoch: 0 - Step: 345 - Loss: 0.741 - Throughput: 572.293 seq/s: 100%"
      }
     },
     "c027c549f513403a8dd0e39497b0c3cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_7269ab27965a4204a63d42dc3bc659ce",
       "max": 3,
       "style": "IPY_MODEL_1d7981b404744ba4b791c98922818cd3"
      }
     },
     "c19d37afbe1245d0b7eeded45c3dc8ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "c38574303a314857af145c9314ce9f70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Step: 112 - throughput: 3309.235 samples/s: 100%",
       "layout": "IPY_MODEL_57ced115d7474cd5b2bc902eb5d61f64",
       "max": 113,
       "style": "IPY_MODEL_0b8bfb3536424f1c8093ad658dd2349c",
       "value": 113
      }
     },
     "c3dd127febf143c9857bead90b7a7595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1261d257152a40a18368f595466aac1f",
        "IPY_MODEL_32bfe2d3c6fd4bc6b7c1ecc8b9f754d4"
       ],
       "layout": "IPY_MODEL_e54f4dab80634ab3ba228a78337fe16c"
      }
     },
     "c440a5eef70547fdbdd428f07aa3ee68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c5a251e538f844e7a2e202c652b3c235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c681ea503e094c149100da1cbf572358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c701f026d5cb415c90f45b15a19f8b0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_3e4f986cad4244f195cac0ce9a86f761",
       "max": 10570,
       "style": "IPY_MODEL_4892ddbb6757414fba7450c4d2895183",
       "value": 10570
      }
     },
     "c7b137b7e85d44f0aff6d434cbbf7df5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c5a251e538f844e7a2e202c652b3c235",
       "style": "IPY_MODEL_573939d58d194a30b18ff15aed870bec",
       "value": " 10570/10570 [00:21&lt;00:00, 496.49it/s]"
      }
     },
     "c7f5d6085c264e66aca41b2941d66c08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8b69b41ac3946d49f9ded898ac17637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 0 - Step: 345 - Loss: 0.778 - Throughput: 579.933 seq/s: 100%",
       "layout": "IPY_MODEL_a833ce9bfc554ef7ae2c462e896b1e47",
       "max": 346,
       "style": "IPY_MODEL_394806f1ef1549019f5e98749e4942c8",
       "value": 346
      }
     },
     "c99a5d9125da4d7a80e14059376f754b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch: 1 - Step: 345 - Loss: 0.664 - Throughput: 570.012 seq/s: 100%",
       "layout": "IPY_MODEL_e69da6300bf54664935e0fb187d7ccf1",
       "max": 346,
       "style": "IPY_MODEL_f8f79b3f429447499b402d770b144d1e",
       "value": 346
      }
     },
     "ca6ab92a0199442eb8c40b1c78995799": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6a55285da8ba42a5b42433a9641f9688",
        "IPY_MODEL_5688c41f7eaf437081e532ba6c98d6eb",
        "IPY_MODEL_bbcc0cb21037499b8e8a4b7adf0b38e9"
       ],
       "layout": "IPY_MODEL_e0df011be6ec4456a68130c56f513f99"
      }
     },
     "caa86e7c770c4b65979cb298694ecc3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cc53dd8973d9476d85280ce0e40bfbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cc9f73329ad44784936f9e39175e2762": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cca7d495a9e24bcc9e2818500e465b91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ccd71a510a9949659751a3620d296894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e258e63ad0794bb88171a81134dd8b64",
       "style": "IPY_MODEL_dfa55558f3914ce0bb4c01ca468b43b6",
       "value": " 346/346 [03:12&lt;00:00,  1.74it/s]"
      }
     },
     "cf662aa184e043cb9616489a749f9d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d174c9c67fec40f0bed694784a211a09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d4613b1f9f4c4682ad7dd0bd99b64ccc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d582c554820a44918b0cd2fa8009bce2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d660db84f39b4ca693057292e4d6e2a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d660f1b593e74ac695623b27234cfd14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfa55558f3914ce0bb4c01ca468b43b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dfe6bcd0588846ed980238cce0ce3f23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e0df011be6ec4456a68130c56f513f99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1e5b2d4470c49478b1de0f8b8d512a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3f50e999fa794c6fbdc6b4911051d16c",
       "style": "IPY_MODEL_24d0269086554bc7a14231dd7d03481a",
       "value": " 2/2 [00:00&lt;00:00, 110.21it/s]"
      }
     },
     "e1fe817426624b48a5a87ba446def36d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37954b48eb164ffe8053637d740ec665",
        "IPY_MODEL_066fa664116849098018e9baa066417d",
        "IPY_MODEL_1344574ddf854e83a8f85ff6c1b69251"
       ],
       "layout": "IPY_MODEL_76537c65be544568b91176fe115fdf4e"
      }
     },
     "e258e63ad0794bb88171a81134dd8b64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e47ee37994894906a0c9ca66c6917a5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4b2f87a8b01461a8cf6478cc98091d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "e54f4dab80634ab3ba228a78337fe16c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e69da6300bf54664935e0fb187d7ccf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6cdeccedbeb4ddca7cab4f0658850d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec1436ebadf94df9a952badc66d9e51d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ecdf7f81055c4e15ba236473d045f570": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ee8982c161d248d2b03cd7e64d09dcf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef0f5be231f94dbeba93712230d0ad87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bc08f9d70ff948d5a43998903a474237",
       "style": "IPY_MODEL_7b6c6d3d77474913b0edc9f4db18f92b",
       "value": " 346/346 [04:56&lt;00:00,  1.17it/s]"
      }
     },
     "ef246036865e45c3ba3637dc1ebbe561": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "efc5029196ca434b869a31ae9c239b57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f03846bf22224128a81aaf092477426f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2380d82578cc45a5ba4cf481f59354fd",
       "style": "IPY_MODEL_feba0c0d24794b558734331478c2d2e5",
       "value": " 346/346 [06:32&lt;00:00,  1.14s/it]"
      }
     },
     "f262cd7b1a3c40bbbad84197e64de588": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4666e5976f847538a3eb3de5de251dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f5f7d6d815b64646bd467d53bed0365c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "f8bbcce113a647cb999fe5e8017e5e5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bb3aa322a3fb4027ac477afb4e12a637",
        "IPY_MODEL_765e2d80436446dd9c3bbc1e68a7923e",
        "IPY_MODEL_8bb6baf370674ce4aa7bd827e01eec43"
       ],
       "layout": "IPY_MODEL_4f41a49093244e499f19edd0b4ce07b9"
      }
     },
     "f8f79b3f429447499b402d770b144d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "fcd7540c0bf04eaa8be606396c899256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37efcdb2a015414397f9d7551c31bd69",
        "IPY_MODEL_1f111acf18bf4dc4a9728746be834514",
        "IPY_MODEL_c7b137b7e85d44f0aff6d434cbbf7df5"
       ],
       "layout": "IPY_MODEL_4fffcf0014b243e389a16493818ae436"
      }
     },
     "fce00d252d75456b9199a4313faf0963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe16a84150d94088a7748459d74e7a57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "feba0c0d24794b558734331478c2d2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ff9adb8c41ce4e97bf8245f9dab30430": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3515d1d1982240f792fa7f4b8c9a4bca",
       "style": "IPY_MODEL_6fb85aeae69f490da819efd2624435d2",
       "value": " 3/3 [09:42&lt;00:00, 194.24s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
